# ğŸ“š Flexible Flash Prefill Attention
âš¡ï¸ Flexible Flash Prefill Attention with **O(1) SRAM complexity** & **O(d/4) register complexity** for large head dim (D > 256), almost **1.2x-1.5x** ğŸ‰ faster than SDPA (EA). (Write for Fun ğŸ‘€~)
